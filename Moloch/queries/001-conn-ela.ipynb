{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to elasticsearch directly\n",
    "\n",
    "It is useful to explore back-end elasticsearch data directly before using Moloch API. For example, exporting all available field names can be useful when writing API queries.\n",
    "\n",
    "Start by importing elastic python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then establish a connection. Multiple hosts can be specified as python list. Verity connectivity with `ping()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(hosts=[\"192.168.10.13:9200\"])\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _cat API and exploring indices\n",
    "\n",
    "We can take a look into available indices via `cat` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green open files_v5         k8W5NFoCTo6LY-FocOZRIQ 2 0   12 0  49.7kb  49.7kb\n",
      "green open queries_v2       LgHRb7qJR5mq7gqyNcwyiQ 1 0    0 0    261b    261b\n",
      "green open stats_v3         w0odpndxR_e-q2drnQx-lA 1 0    1 0  12.8kb  12.8kb\n",
      "green open hunts_v1         rn2XmMD_SuCQcgFvPPx8nw 1 0    0 0    261b    261b\n",
      "green open users_v6         pnagVE3KTHu58x1oX6Vm7Q 1 0    1 0   6.5kb   6.5kb\n",
      "green open dstats_v3        3FcI3RT4RGKSgrnWrBB1Iw 2 0 1330 0 441.1kb 441.1kb\n",
      "green open fields_v2        pK6ODUppSnuSlr1KZfK0Pg 1 0  307 2  97.4kb  97.4kb\n",
      "green open sequence_v2      GSKzXikFTNGCEDhOS2luYQ 1 0    1 0   2.6kb   2.6kb\n",
      "green open sessions2-190522 bO8ol02FSVGR75G-Z0_3RA 1 0 1609 0   2.2mb   2.2mb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices = es.cat.indices()\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, it returns a text string. We could split it by newline to make it usable in a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "['green', 'open', 'files_v5', 'k8W5NFoCTo6LY-FocOZRIQ', '2', '0', '12', '0', '49.7kb', '49.7kb']\n",
      "----------\n",
      "['green', 'open', 'queries_v2', 'LgHRb7qJR5mq7gqyNcwyiQ', '1', '0', '0', '0', '261b', '261b']\n",
      "----------\n",
      "['green', 'open', 'stats_v3', 'w0odpndxR_e-q2drnQx-lA', '1', '0', '1', '0', '12.8kb', '12.8kb']\n",
      "----------\n",
      "['green', 'open', 'hunts_v1', 'rn2XmMD_SuCQcgFvPPx8nw', '1', '0', '0', '0', '261b', '261b']\n",
      "----------\n",
      "['green', 'open', 'users_v6', 'pnagVE3KTHu58x1oX6Vm7Q', '1', '0', '1', '0', '6.5kb', '6.5kb']\n",
      "----------\n",
      "['green', 'open', 'dstats_v3', '3FcI3RT4RGKSgrnWrBB1Iw', '2', '0', '1330', '0', '441.1kb', '441.1kb']\n",
      "----------\n",
      "['green', 'open', 'fields_v2', 'pK6ODUppSnuSlr1KZfK0Pg', '1', '0', '307', '2', '97.4kb', '97.4kb']\n",
      "----------\n",
      "['green', 'open', 'sequence_v2', 'GSKzXikFTNGCEDhOS2luYQ', '1', '0', '1', '0', '2.6kb', '2.6kb']\n",
      "----------\n",
      "['green', 'open', 'sessions2-190522', 'bO8ol02FSVGR75G-Z0_3RA', '1', '0', '1609', '0', '2.2mb', '2.2mb']\n",
      "********************\n",
      "['files_v5', 'queries_v2', 'stats_v3', 'hunts_v1', 'users_v6', 'dstats_v3', 'fields_v2', 'sequence_v2', 'sessions2-190522']\n"
     ]
    }
   ],
   "source": [
    "data = indices.split(\"\\n\")\n",
    "newIdxList = []\n",
    "for idx in data:\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    print(\"-\"*10)\n",
    "    idx = idx.split()\n",
    "    newIdxList.append(idx[2])\n",
    "    print(idx)\n",
    "print(\"*\"*20)\n",
    "print(newIdxList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could get structured data by simply specifying `format` query parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'files_v5',\n",
       "  'uuid': 'k8W5NFoCTo6LY-FocOZRIQ',\n",
       "  'pri': '2',\n",
       "  'rep': '0',\n",
       "  'docs.count': '12',\n",
       "  'docs.deleted': '0',\n",
       "  'store.size': '49.7kb',\n",
       "  'pri.store.size': '49.7kb'},\n",
       " {'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'queries_v2',\n",
       "  'uuid': 'LgHRb7qJR5mq7gqyNcwyiQ',\n",
       "  'pri': '1',\n",
       "  'rep': '0',\n",
       "  'docs.count': '0',\n",
       "  'docs.deleted': '0',\n",
       "  'store.size': '261b',\n",
       "  'pri.store.size': '261b'},\n",
       " {'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'stats_v3',\n",
       "  'uuid': 'w0odpndxR_e-q2drnQx-lA',\n",
       "  'pri': '1',\n",
       "  'rep': '0',\n",
       "  'docs.count': '1',\n",
       "  'docs.deleted': '0',\n",
       "  'store.size': '12.8kb',\n",
       "  'pri.store.size': '12.8kb'},\n",
       " {'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'hunts_v1',\n",
       "  'uuid': 'rn2XmMD_SuCQcgFvPPx8nw',\n",
       "  'pri': '1',\n",
       "  'rep': '0',\n",
       "  'docs.count': '0',\n",
       "  'docs.deleted': '0',\n",
       "  'store.size': '261b',\n",
       "  'pri.store.size': '261b'},\n",
       " {'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'users_v6',\n",
       "  'uuid': 'pnagVE3KTHu58x1oX6Vm7Q',\n",
       "  'pri': '1',\n",
       "  'rep': '0',\n",
       "  'docs.count': '1',\n",
       "  'docs.deleted': '0',\n",
       "  'store.size': '6.5kb',\n",
       "  'pri.store.size': '6.5kb'},\n",
       " {'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'dstats_v3',\n",
       "  'uuid': '3FcI3RT4RGKSgrnWrBB1Iw',\n",
       "  'pri': '2',\n",
       "  'rep': '0',\n",
       "  'docs.count': '1348',\n",
       "  'docs.deleted': '0',\n",
       "  'store.size': '435.8kb',\n",
       "  'pri.store.size': '435.8kb'},\n",
       " {'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'fields_v2',\n",
       "  'uuid': 'pK6ODUppSnuSlr1KZfK0Pg',\n",
       "  'pri': '1',\n",
       "  'rep': '0',\n",
       "  'docs.count': '307',\n",
       "  'docs.deleted': '2',\n",
       "  'store.size': '97.4kb',\n",
       "  'pri.store.size': '97.4kb'},\n",
       " {'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'sequence_v2',\n",
       "  'uuid': 'GSKzXikFTNGCEDhOS2luYQ',\n",
       "  'pri': '1',\n",
       "  'rep': '0',\n",
       "  'docs.count': '1',\n",
       "  'docs.deleted': '0',\n",
       "  'store.size': '2.6kb',\n",
       "  'pri.store.size': '2.6kb'},\n",
       " {'health': 'green',\n",
       "  'status': 'open',\n",
       "  'index': 'sessions2-190522',\n",
       "  'uuid': 'bO8ol02FSVGR75G-Z0_3RA',\n",
       "  'pri': '1',\n",
       "  'rep': '0',\n",
       "  'docs.count': '1623',\n",
       "  'docs.deleted': '0',\n",
       "  'store.size': '2.3mb',\n",
       "  'pri.store.size': '2.3mb'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices2 = es.cat.indices(format=\"json\")\n",
    "indices2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do a lot of cool things by simply looping over the data structure. For example, check index health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in indices2:\n",
    "    if idx[\"health\"] != \"green\":\n",
    "        print(idx[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check document counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'health': 'green', 'status': 'open', 'index': 'dstats_v3', 'uuid': '3FcI3RT4RGKSgrnWrBB1Iw', 'pri': '2', 'rep': '0', 'docs.count': '1348', 'docs.deleted': '0', 'store.size': '435.8kb', 'pri.store.size': '435.8kb'}\n",
      "{'health': 'green', 'status': 'open', 'index': 'fields_v2', 'uuid': 'pK6ODUppSnuSlr1KZfK0Pg', 'pri': '1', 'rep': '0', 'docs.count': '307', 'docs.deleted': '2', 'store.size': '97.4kb', 'pri.store.size': '97.4kb'}\n",
      "{'health': 'green', 'status': 'open', 'index': 'sessions2-190522', 'uuid': 'bO8ol02FSVGR75G-Z0_3RA', 'pri': '1', 'rep': '0', 'docs.count': '1623', 'docs.deleted': '0', 'store.size': '2.3mb', 'pri.store.size': '2.3mb'}\n"
     ]
    }
   ],
   "source": [
    "for idx in indices2:\n",
    "    if int(idx[\"docs.count\"]) > 100:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use list comprehensions to awesome one-line conditional data collection. Like, extract all Moloch session indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sessions2-190522']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxList = [i[\"index\"] for i in indices2 if \"sessions2\" in i[\"index\"]]\n",
    "idxList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Moloch data\n",
    "\n",
    "We cannot write API (nor normal) queries without knowing the field names we can play with. At the moment of writing this notebook, the best way to extract all fields is by running elasticsearch query against `fields` index. Note that this is an empty query. `size` parameter simply limits the maximum number of returned items. `3000` is simply a large enough number to ensure we get all fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = es.search(\"fields\", params={\"size\":3000})\n",
    "#print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = [f[\"_source\"] for f in fields[\"hits\"][\"hits\"]]\n",
    "#print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "justnames = [f[\"dbField2\"] for f in raw if f[\"dbField2\"]]\n",
    "justnames = sorted(justnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'asnall',\n",
       " 'asset',\n",
       " 'assetCnt',\n",
       " 'cert.alt',\n",
       " 'cert.altCnt',\n",
       " 'cert.hash',\n",
       " 'cert.issuerCN',\n",
       " 'cert.issuerON',\n",
       " 'cert.notAfter']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 307 fields in database\n"
     ]
    }
   ],
   "source": [
    "print(\"there are {} fields in database\".format(len(justnames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "* Extract all `dns` and `http` fields into dedicated python lists;\n",
    "    * How many fields are in either list?\n",
    "* **advanced** Explore pcap file list in moloch database;\n",
    "    * Print all file names with first packet timestamp;\n",
    "    * Run this query against singlehost or buildbox if this vagrant environment does not have enough pcap files;\n",
    "    * Load additional pcap files from [here](https://malware-traffic-analysis.net/2019/index.html) (zip file password is always INFECTED) and get first packet timestamps from each file;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
