{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Elastic via Python API\n",
    "\n",
    "Start by importing elasticsearch library. Make sure it is installed with `python3 -m pip install --user elasticsearch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecing and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a connection. It will default to `localhost:9200` if `hosts` argument is omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(hosts=[\"192.168.10.14:9200\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always make sure your cluster connection is actually alive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing your first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'second',\n",
       " '_type': 'doc',\n",
       " '_id': 'BBBB',\n",
       " '_version': 3,\n",
       " 'result': 'updated',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 2,\n",
       " '_primary_term': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = {\n",
    "    \"field1\": \"val1\",\n",
    "    \"field2\": \"val1\",\n",
    "    \"field3\": 123\n",
    "}\n",
    "es.index(\"second\", doc_type=\"doc\", body=document, id=\"BBBB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that elasticsearch library is just a wrapper for talking to HTTP API, so prior example is roughly equal to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'second', '_type': 'doc', '_id': 'BBBB', '_version': 4, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 3, '_primary_term': 1}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "url = \"http://192.168.10.14:9200/second/doc/BBBB\"\n",
    "headers = { \"Content-Type\": \"application/json\" }\n",
    "\n",
    "resp = requests.post(url, data=json.dumps(document), headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then retreive it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'second', '_type': 'doc', '_id': 'BBBB', '_version': 4, '_seq_no': 3, '_primary_term': 1, 'found': True, '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}}\n"
     ]
    }
   ],
   "source": [
    "newdoc = es.get(\"second\", doc_type=\"doc\", id=\"BBBB\")\n",
    "print(newdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic attaches fair amount of meta information. Actual souce document is in `_source` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'field1': 'val1', 'field2': 'val1', 'field3': 123}\n"
     ]
    }
   ],
   "source": [
    "newdoc = newdoc[\"_source\"]\n",
    "print(newdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch uses HTTP and transport protocol, so indexing individual documents is fairly expensive. Especially when talking about IDS logs. Proper way is to use `bulk` API.\n",
    "\n",
    "See:\n",
    " * https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html\n",
    "\n",
    "Bulk format requires metadata line before each document to indicate what action should be taken, which index used, etc. Consider the illustration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    \"index\": {\n",
    "        \"_index\": \"third\",\n",
    "        \"_type\": \"_doc\",\n",
    "        \"_id\": \"CCCC\"\n",
    "    }\n",
    "}\n",
    "\n",
    "bulk = []\n",
    "i = 0\n",
    "for i in range(100):\n",
    "    meta = {\n",
    "        \"index\": {\n",
    "            \"_index\": \"third\",\n",
    "            \"_type\": \"_doc\",\n",
    "            \"_id\": i\n",
    "        }\n",
    "    }\n",
    "    doc = {\n",
    "        \"message\": \"this is message {}\".format(i),\n",
    "        \"count\": i\n",
    "    }\n",
    "    \n",
    "    bulk.append(meta)\n",
    "    bulk.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the message structure by simply printing first 10 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 0}}\n",
      "{'message': 'this is message 0', 'count': 0}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 1}}\n",
      "{'message': 'this is message 1', 'count': 1}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 2}}\n",
      "{'message': 'this is message 2', 'count': 2}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 3}}\n",
      "{'message': 'this is message 3', 'count': 3}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': 4}}\n",
      "{'message': 'this is message 4', 'count': 4}\n"
     ]
    }
   ],
   "source": [
    "for msg in bulk[0:10]:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then send the bulk to elasticsearch. And verify that everything was indexed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "resp = es.bulk(bulk)\n",
    "#print(json.dumps(resp, indent=2))\n",
    "print(resp[\"errors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of each indexed document will be returned, so we can check a subset of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '0', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 600, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '1', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 601, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '2', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 602, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '3', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 603, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '4', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 604, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '5', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 605, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '6', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 606, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '7', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 607, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '8', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 608, '_primary_term': 1, 'status': 200}}\n",
      "{'index': {'_index': 'third', '_type': '_doc', '_id': '9', '_version': 7, 'result': 'updated', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 609, '_primary_term': 1, 'status': 200}}\n"
     ]
    }
   ],
   "source": [
    "for result in resp[\"items\"][0:10]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your first search query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run a search against this index, looking for documents where `count` field is `>= 12` or `<= 20`. Only three results are reported back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['took', 'timed_out', '_shards', 'hits'])\n",
      "dict_keys(['total', 'max_score', 'hits'])\n"
     ]
    }
   ],
   "source": [
    "results = es.search(index=\"third\", doc_type=\"_doc\", body={\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"range\": {\n",
    "            \"count\": {\n",
    "                \"gte\": 12,\n",
    "                \"lte\": 20,\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "print(results.keys())\n",
    "print(results[\"hits\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'third', '_type': '_doc', '_id': '12', '_score': 1.0, '_source': {'message': 'this is message 12', 'count': 12}}\n",
      "{'_index': 'third', '_type': '_doc', '_id': '13', '_score': 1.0, '_source': {'message': 'this is message 13', 'count': 13}}\n",
      "{'_index': 'third', '_type': '_doc', '_id': '14', '_score': 1.0, '_source': {'message': 'this is message 14', 'count': 14}}\n"
     ]
    }
   ],
   "source": [
    "if not results[\"timed_out\"]:\n",
    "    for result in results[\"hits\"][\"hits\"]:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that omitting `_id` will cause elastic to autogenerate one. However, if you index the same log again, then having a distinct ID will cause the old one to be updated. Otherwise, the second indexing round will duplicate the log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the second indexing call updates the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'fourth',\n",
       " '_type': 'doc',\n",
       " '_id': 'BBBB',\n",
       " '_version': 8,\n",
       " 'result': 'updated',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 7,\n",
       " '_primary_term': 1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.index(index=\"fourth\", doc_type=\"doc\", body=document, id=\"BBBB\")\n",
    "es.index(index=\"fourth\", doc_type=\"doc\", body=document, id=\"BBBB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here two separate documents will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'fifth',\n",
       " '_type': 'doc',\n",
       " '_id': '13qrD3ABOj6xcWqo7S_q',\n",
       " '_version': 1,\n",
       " 'result': 'created',\n",
       " '_shards': {'total': 2, 'successful': 1, 'failed': 0},\n",
       " '_seq_no': 3,\n",
       " '_primary_term': 1}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.index(index=\"fifth\", doc_type=\"doc\", body=document)\n",
    "es.index(index=\"fifth\", doc_type=\"doc\", body=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = es.cat.indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify this via `_cat` API to see that *fourth* index has only one document while *fifth* has more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow open third  eYOOxir8TG2nOEBgy9i5JQ 1 1 100 400 29.5kb 29.5kb\n",
      "yellow open fifth  z6oY9K_rSvWnyLabwhW5DQ 1 1   2   0  4.4kb  4.4kb\n",
      "yellow open fourth gPJphi7_QBq8vKjSDzarUg 1 1   1   1 11.2kb 11.2kb\n",
      "yellow open second d2blTfNLTd6AJjvHfIID6Q 1 1   1   1  5.8kb  5.8kb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can verify the same thing by querying these indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 4, 'relation': 'eq'},\n",
       "  'max_score': 1.0,\n",
       "  'hits': [{'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': '1HqED3ABOj6xcWqoby8C',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': '1XqED3ABOj6xcWqoby87',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': '1nqrD3ABOj6xcWqo7S_K',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}},\n",
       "   {'_index': 'fifth',\n",
       "    '_type': 'doc',\n",
       "    '_id': '13qrD3ABOj6xcWqo7S_q',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}}]}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.search(index=\"fifth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 1, 'relation': 'eq'},\n",
       "  'max_score': 1.0,\n",
       "  'hits': [{'_index': 'fourth',\n",
       "    '_type': 'doc',\n",
       "    '_id': 'BBBB',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'field1': 'val1', 'field2': 'val1', 'field3': 123}}]}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.search(index=\"fourth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that we can manage pretty much anything via elastic python API. For example, we could create mapping template programmatically. This is a typical base template similar to what logstash creates. However, it is easier to customize it this way. For example, instead of applying only to `logstash-*` index pattern, we also added `events-*` and `suricata-*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {\n",
    "    \"index\": {\n",
    "        \"number_of_shards\": 3,\n",
    "        \"number_of_replicas\": 0,\n",
    "        \"refresh_interval\": \"30s\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFAULT_PROPERTIES = {\n",
    "    \"@timestamp\": {\n",
    "        \"type\": \"date\",\n",
    "        \"format\": \"strict_date_optional_time||epoch_millis||date_time\"\n",
    "    },\n",
    "    \"@version\": {\n",
    "        \"type\": \"keyword\"\n",
    "    },\n",
    "    \"ip\": {\n",
    "        \"type\": \"ip\"\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFAULT_MAPPINGS = {\n",
    "    \"dynamic_templates\": [\n",
    "        {\n",
    "            \"message_field\": {\n",
    "                \"path_match\": \"message\",\n",
    "                \"mapping\": {\n",
    "                    \"norms\": False,\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"match_mapping_type\": \"string\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"string_fields\": {\n",
    "                \"mapping\": {\n",
    "                    \"norms\": False,\n",
    "                    \"type\": \"text\",\n",
    "                    \"fields\": {\n",
    "                        \"keyword\": {\n",
    "                            \"type\": \"keyword\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"match_mapping_type\": \"string\",\n",
    "                \"match\": \"*\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"properties\": DEFAULT_PROPERTIES\n",
    "}\n",
    "\n",
    "DEFAULT_PATTERNS = [\n",
    "    \"logstash-*\",\n",
    "    \"events-*\",\n",
    "    \"suricata-*\"\n",
    "]\n",
    "\n",
    "DEFAULT_TEMPLATE = {\n",
    "    \"order\": 0,\n",
    "    \"version\": 0,\n",
    "    \"index_patterns\": DEFAULT_PATTERNS,\n",
    "    \"settings\": DEFAULT_SETTINGS,\n",
    "    \"mappings\": DEFAULT_MAPPINGS,\n",
    "    \"aliases\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order': 0, 'version': 0, 'index_patterns': ['logstash-*', 'events-*', 'suricata-*'], 'settings': {'index': {'number_of_shards': 3, 'number_of_replicas': 0, 'refresh_interval': '30s'}}, 'mappings': {'dynamic_templates': [{'message_field': {'path_match': 'message', 'mapping': {'norms': False, 'type': 'text'}, 'match_mapping_type': 'string'}}, {'string_fields': {'mapping': {'norms': False, 'type': 'text', 'fields': {'keyword': {'type': 'keyword'}}}, 'match_mapping_type': 'string', 'match': '*'}}], 'properties': {'@timestamp': {'type': 'date', 'format': 'strict_date_optional_time||epoch_millis||date_time'}, '@version': {'type': 'keyword'}, 'ip': {'type': 'ip'}}}, 'aliases': {}}\n"
     ]
    }
   ],
   "source": [
    "print(DEFAULT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "tpl = DEFAULT_TEMPLATE\n",
    "resp = es.indices.put_template(\"default\", body=tpl)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'default': {'order': 0, 'version': 0, 'index_patterns': ['logstash-*', 'events-*', 'suricata-*'], 'settings': {'index': {'number_of_shards': '3', 'number_of_replicas': '0', 'refresh_interval': '30s'}}, 'mappings': {'dynamic_templates': [{'message_field': {'path_match': 'message', 'mapping': {'norms': False, 'type': 'text'}, 'match_mapping_type': 'string'}}, {'string_fields': {'mapping': {'norms': False, 'type': 'text', 'fields': {'keyword': {'type': 'keyword'}}}, 'match_mapping_type': 'string', 'match': '*'}}], 'properties': {'@timestamp': {'format': 'strict_date_optional_time||epoch_millis||date_time', 'type': 'date'}, 'ip': {'type': 'ip'}, '@version': {'type': 'keyword'}}}, 'aliases': {}}}\n"
     ]
    }
   ],
   "source": [
    "resp = es.indices.get_template(\"default\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Templates can be layered on top of each other, with `order` value specifying the apply precedence. Therefore, we can create a base template that applies to all index patterns, and then create a more specific template for indices containing a particular event type. Former ensures that basic settings like sharding and replicas are configured properly, along with sane default mappings. Latter can be used to explicitly map certain fields. For example, we might wish suricata `src_ip` and `dest_ip` fields to be mapped as `ip` datatype, to enable subnet queries. And to map `payload` field as binary for more efficient storage. By default they would be mapped as strings. However we do not want the same logic to be applied to other indices, line `windows-*` or as they may have same fields with conflicting types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURICATA_TEMPLATE = {\n",
    "  \"order\": 10,\n",
    "  \"version\": 0,\n",
    "  \"index_patterns\": [\n",
    "    \"suricata-*\",\n",
    "    \"logstash-*\"\n",
    "  ],\n",
    "  \"mappings\":{\n",
    "    \"properties\": {\n",
    "      \"src_ip\": { \n",
    "        \"type\": \"ip\",\n",
    "        \"fields\": {\n",
    "          \"keyword\" : { \"type\": \"keyword\", \"ignore_above\": 256 }\n",
    "        }\n",
    "      },\n",
    "      \"dest_ip\": { \n",
    "        \"type\": \"ip\",\n",
    "        \"fields\": {\n",
    "          \"keyword\" : { \"type\": \"keyword\", \"ignore_above\": 256 }\n",
    "        }\n",
    "      },\n",
    "      \"payload\": { \"type\": \"binary\" }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that IP fields have a dual-mapping. In other words, this template also create `src_ip.keyword` and `dest_ip.keyword` fields. Reason is simple - some frontend tools assume default logstash mappings where everything is a string, and thus execute string aggregations against `.keyword` fields. This template should give the best of both worlds. Raw field has correct IP mapping which means more efficient storage and enables subnet queries. Dual mapping ensures that regular `term` aggregations still work and are compatible with tools like `evebox` and `scirius`. `Payload` is a base64 encoded blob, so there is no point in tokenizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "tpl = SURICATA_TEMPLATE\n",
    "resp = es.indices.put_template(\"default\", body=tpl)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
